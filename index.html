import requests
from bs4 import BeautifulSoup

def find_contact_info(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # Check for successful request

        soup = BeautifulSoup(response.content, 'html.parser')

        # Find the careers page (you may need to manually specify the path)
        careers_link = None
        for link in soup.find_all('a', href=True):
            if 'careers' in link['href'].lower() or 'jobs' in link['href'].lower():
                careers_link = link['href']
                if not careers_link.startswith('http'):
                    careers_link = url + careers_link  # Handle relative URLs
                break


        if careers_link:
            print(f"Careers page found: {careers_link}")
            careers_response = requests.get(careers_link)
            careers_soup = BeautifulSoup(careers_response.content, 'html.parser')
            
            # Example for scraping job postings and contacts:
            for job_listing in careers_soup.find_all('div', class_='job-listing'):
                title = job_listing.find('h2').text
                contact_info = job_listing.find_all(text=lambda x: '@' in x or 'Phone:' in x)

                # Display job title and contact info
                print(f"Job Title: {title}")
                for info in contact_info:
                    print(f"Contact Info: {info.strip()}")

    except Exception as e:
        print(f"Error fetching data from {url}: {str(e)}")

# Example usage:
find_contact_info('https://example-private-practice.com')
